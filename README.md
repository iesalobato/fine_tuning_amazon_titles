# Treinando um Modelo para Responder Perguntas com o Dataset Amazon Titles

## üìù Descri√ß√£o do Projeto

Este projeto foi desenvolvido como parte do Tech Challenge da **P√≥s-Gradua√ß√£o em IA para Devs**. O objetivo principal √© realizar o fine-tuning de um *foundation model* (neste caso, `mistralai/Mistral-7B-Instruct-v0.3`) para uma tarefa espec√≠fica: gerar descri√ß√µes de produtos da Amazon a partir de seus t√≠tulos.

O processo utiliza a t√©cnica de **LoRA** (Low-Rank Adaptation) para treinar eficientemente o modelo em um ambiente com recursos limitados, como o Google Colab.

### Objetivos Conformes ao Desafio:
- Executar o fine-tuning de um *foundation model* (Mistral-7B).
- Utilizar o dataset "The Amazon Titles-1.3MM", especificamente o arquivo `trn.json`.
- Treinar o modelo para, a partir de um prompt com o t√≠tulo de um produto, gerar sua respectiva descri√ß√£o.

## üõ†Ô∏è Tecnologias Utilizadas

- **Linguagem:** Python 3.10+
- **Ambiente:** Google Colab (com GPU A100 do plano Pro)

## ‚öôÔ∏è Configura√ß√£o do Ambiente
1.  **Hardware:** Este projeto requer um ambiente com GPU. Recomenda-se o uso do Google Colab com uma GPU T4, V100 ou, idealmente, A100.
2.  **Depend√™ncias:** As bibliotecas necess√°rias ser√£o instaladas quando o c√≥digo do Google Colab for executado.

## üöÄ Como Executar

1.  **Clone o Reposit√≥rio:**
    ```bash
    git clone https://github.com/iesalobato/fine_tuning_amazon_titles.git
    ```

2.  **Abra o Notebook no Google Colab:** Fa√ßa o upload do arquivo `.ipynb` para o seu ambiente Colab e configure o ambiente de execu√ß√£o para usar uma GPU.

3.  **Autentica√ß√£o no Hugging Face:** Para baixar o modelo `mistralai/Mistral-7B-Instruct-v0.3`, √© necess√°rio autenticar sua conta do Hugging Face. Execute a c√©lula de login e insira seu token de acesso. Lembre-se que sua conta precisa ter acesso pr√©vio ao modelo.

4.  **Execute as C√©lulas:** Execute as c√©lulas do notebook em ordem. O fluxo principal √©:
    * **Instala√ß√£o de Depend√™ncias:** Instala todas as bibliotecas.
    * **Carregamento e Limpeza dos Dados:** Baixa o dataset do Google Drive, carrega uma amostra, remove duplicatas e formata os prompts.
    * **Carregamento do Modelo e Tokenizador:** Carrega o Mistral-7B com quantiza√ß√£o em 4-bit.
    * **Fine-Tuning:** Executa o treinamento com o `SFTTrainer` e os par√¢metros otimizados.
    * **Avalia√ß√£o e Demonstra√ß√£o:** Carrega o modelo treinado e apresenta os resultados, incluindo uma interface interativa.

## ‚úíÔ∏è Equipe:
- I√™sa Lobato
- Rilson Soares
- Ismael Costa
- Felipe Vieira
